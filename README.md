# ü¶∏ Demo LLM : Le Voyage de l'Apprenti AI-Agent

Bienvenue dans ce d√©p√¥t p√©dagogique con√ßu pour explorer et d√©montrer les capacit√©s des Large Language Models (LLM) √† travers un cas d'usage fil rouge ludique : l'univers **Marvel**.

Ce projet est con√ßu pour √™tre **didactique** et **progressif**. Il part d'un simple appel API pour aboutir √† une architecture d'entreprise complexe utilisant des agents autonomes et le protocole **MCP (Model Context Protocol)**.

---

## üèóÔ∏è Architecture & Philosophie

*   **Approche Pas-√†-Pas** : Le code est d√©coup√© en **Phases (A √† E)**, elles-m√™mes divis√©es en **√âtapes num√©rot√©es**.
*   **Ind√©pendance** : Chaque script est con√ßu pour √™tre le plus autonome possible.
*   **S√©paration Logic/UI** : Distinguo clair entre le cerveau (Serveur/Scripts) et les muscles (Streamlit).
*   **Aesthetics First** : Les interfaces visent un rendu premium pour une exp√©rience utilisateur moderne.

---

## üöÄ Guide de D√©marrage

1.  **Installation** :
    ```bash
    python -m venv .venv
    .venv\Scripts\activate
    pip install -r requirements.txt
    ```
2.  **Configuration** :
    Cr√©ez un fichier `.env` :
    ```env
    LLM_MODEL=gpt-4o-mini
    LLM_API_KEY=sk-...
    ```

---

## ü™ú D√©tail des Phases

### Phase A : Les Fondations (Prompting & M√©moire)
*Objectif : Comprendre comment envoyer une requ√™te et g√©rer une conversation.*

*   **A01 : Simple API**
    Le point de d√©part. Une question, une r√©ponse brute via l'API.
    - **Test** : Lancer `python A01_simple_api.py`.
    ![Question et R√©ponse](doc/A01_simple_api_Question_et_reponse.png)

*   **A02 : Chat Terminal**
    Ajout de la m√©moire. Le LLM se souvient des √©changes pr√©c√©dents dans une boucle de chat en ligne de commande.
    - **Test** : Lancer `python A02_chat_terminal.py`.
    ![Conversation Terminal](doc/A02_chat_terminal_conversation.png)

*   **A03 : Streamlit Chat**
    Passage au Web. Une interface de chat moderne, fluide et persistante.
    - **Test** : Lancer `streamlit run A03_streamlit_chat.py`.
    ![Interface Streamlit](doc/A03_streamlit_chat_conversation.png)
    *Architecture :*
    ![Diagramme A03](doc/A03_streamlit_chat_diagramme.png)

---

### Phase B : Connaissance & RAG (Retrieval Augmented Generation)
*Objectif : Connecter le LLM √† vos propres documents (Fiches h√©ros Marvel).*

*   **B01/B02 : RAG (Base de Donn√©es Vectorielle)**
    Le LLM "lit" des documents texte et r√©pond en s'appuyant sur ces connaissances tierces.
    - **Test** : 
        1. G√©rer les donn√©es : `python B01_generate_data.py` (cr√©e le dossier `data/`).
        2. Indexer : `python B02a_create_vector_db.py` (cr√©e l'index FAISS).
        3. Interroger : `streamlit run B02c_streamlit_rag.py`.
    ![RAG en action](doc/B02_query_rag_conversation.png)
    *Fonctionnement :*
    ![Diagramme RAG](doc/B02_query_rag_diagramme.png)

*   **B03 : LangGraph Routing**
    Introduction √† la logique d'Agent. Un routeur intelligent d√©cide si la question n√©cessite le RAG ou une r√©ponse directe.
    - **Test** : Lancer `streamlit run B03_langgraph_routing.py`.
    ![Routage Domaine](doc/B03_langgraph_routing_branche_domaine.png)
    ![Routage Hors-Domaine](doc/B03_langgraph_routing_branche_hors_domaine.png)
    *Logique du graphe :*
    ![Diagramme Routage](doc/B03_langgraph_routing_diagramme.png)

---

### Phase C : Donn√©es Structur√©es (Text-to-SQL)
*Objectif : Interroger des bases de donn√©es SQL d'entreprise en langage naturel.*

*   **C01 : Streamlit SQL**
    Le LLM convertit une demande ("Quels films pour Thor ?") en requ√™te SQL complexe.
    - **Test** :
        1. Setup DB : `python C01a_setup_marvel_sql.py`.
        2. App : `streamlit run C01b_streamlit_sql.py`.
    ![Tableau SQL](doc/C01_streamlit_sql_tableau.png)
    *Flux :*
    ![Diagramme SQL](doc/C01_streamlit_sql_diagramme.png)

*   **C02 : Data Catalog Explorer**
    Le LLM explore d'abord un catalogue de m√©tadonn√©es pour localiser l'information avant d'agir.
    - **Test** :
        1. Setup : `python C02a_setup_catalog.py`.
        2. App : `streamlit run C02b_streamlit_catalog.py`.
    ![Tableau Catalogue](doc/C02_streamlit_catalog_tableau.png)
    *Flux :*
    ![Diagramme Catalogue](doc/C02_streamlit_catalog_diagramme.png)

---

### Phase D : Action & Outils (Tool Calling)
*Objectif : Transformer le LLM en Agent capable d'agir sur le monde r√©el.*

*   **D01 : Agent avec Outils (Calculateur de Combat)**
    L'agent d√©cide d'appeler un microservice externe pour obtenir une donn√©e technique.
    - **Test** :
        1. Lancer le service : `python D01a_combat_service.py` (Port 8002).
        2. Lancer l'Agent : `streamlit run D01b_streamlit_tools.py`.
    ![Tool Calling](doc/D01_streamlit_tools_conversation.png)
    *S√©quence :*
    ![Diagramme Tools](doc/D01_streamlit_tools_diagramme.png)

*   **D02 : Data Visualization Agent**
    L'agent g√©n√®re dynamiquement du code Python pour visualiser des donn√©es √† la vol√©e.
    - **Test** : Lancer `streamlit run D02_streamlit_charts.py`.
    ![Graphique](doc/D02_streamlit_charts_graphique.png)
    *Processus :*
    ![Diagramme Charts](doc/D02_streamlit_charts_diagramme.png)

---

### Phase E : Industrialisation avec MCP (Model Context Protocol)
*Objectif : Standardiser l'√©cosyst√®me IA via le protocole ouvert MCP d'Anthropic.*

*   **E01 : Discovery MCP (Outils dynamiques)**
    Le client d√©couvre les capacit√©s du serveur (outils) dynamiquement √† la connexion.
    - **Test** : Serveur `E01a_mcp_server.py` + Client `E01b_streamlit_mcp.py`.
    ![Discovery UI](doc/E01_MCP_ToolDiscovery_streamlit.png)
    *Flux :*
    ![Diagramme E01](doc/E01_MCP_ToolDiscovery_graphique.png)

*   **E02 : Agent Autonome MCP**
    Un agent orchestr√© par LangGraph utilise les outils standardis√©s MCP.
    - **Test** : Serveur `E01a_mcp_server.py` + Agent `E02_streamlit_mcp_agent.py`.
    ![Agent UI](doc/E02_MCP_ToolAgentUse_streamlit.png)
    *Flux :*
    ![Diagramme E02](doc/E02_MCP_ToolAgentUse_graphique.png)

*   **E03 : Ressources MCP (Acc√®s aux fichiers)**
    Lecture de fichiers Markdown ou logs distants via le protocole standardis√©.
    - **Test** : Serveur `E03a_mcp_server_resources.py` + App `E03b_streamlit_mcp_resources.py`.
    ![Resources UI](doc/E03_MCP_Resources_streamlit.png)
    *Flux :*
    ![Diagramme E03](doc/E03_MCP_Resources_graphique.png)

*   **E04 : Prompt Templates MCP**
    Utilisation de mod√®les de prompts partag√©s par le serveur pour guider l'agent.
    - **Test** : Serveur `E04a_mcp_server_templates.py` + App `E04b_streamlit_mcp_templates.py`.
    ![Templates UI](doc/E04_MCP_ResourceTemplate_streamlit.png)
    *Flux :*
    ![Diagramme E04](doc/E04_MCP_ResourceTemplate_graphique.png)

*   **E05 : Async Monitoring & Progress MCP**
    Suivi de t√¢ches longues asynchrones avec barres de progression temps r√©el via MCP.
    - **Test** : Serveur `E05a_mcp_server_progress.py` + App `E05b_streamlit_mcp_progress.py`.
    ![Progress UI](doc/E05_MCP_Async_streamlit.png)
    *Flux :*
    ![Diagramme E05](doc/E05_MCP_Async_graphique.png)

*   **E06 : Notifications Temps R√©el (Server Push)**
    D√©monstration ultime : Le serveur pousse une notification de changement de donn√©es sans demande du client.
    - **Test** :
        1. Serveur : `python E06a_mcp_server_notifications.py`.
        2. Client : `python E06b_mcp_client_html.py` (G√©n√®re `E06_viewer.html`).
        3. Admin : `streamlit run E06c_mcp_server_admin.py` (Ajoutez un ennemi).
        4. Voir le viewer HTML se mettre √† jour instantan√©ment.
    ![Notification UI](doc/E06_MCP_notification_maj.png)
    *Architecture :*
    ![Graphique E06](doc/E06_MCP_notification_graphique.png)

---

## üõ†Ô∏è Outils & M√©thodologie
Ce projet a √©t√© r√©alis√© avec l'assistance de **Google Antigravity** pour le codage, la structuration et la documentation premium.
Le code utilise les derniers standards (LangGraph, MCP, SSE) pour offrir une architecture "Future-Proof".
